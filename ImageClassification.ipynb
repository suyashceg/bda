{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import cv2\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "dsSaveDir = 'npyData'\n",
    "modelSaveDir = 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load images and labels if they have already been created\n",
    "    splits = X_train, X_test, X_valid, y_train, y_test, y_valid = [\n",
    "        np.load(dsSaveDir + '/{}.npy'.format(i+1)) for i in range(6)]\n",
    "\n",
    "except:\n",
    "    def glob_images(dir):\n",
    "        return glob.glob(os.path.abspath(dir + '/*'))\n",
    "\n",
    "    def read_images(files):\n",
    "        return [cv2.cvtColor(cv2.imread(file), cv2.COLOR_BGR2RGB) for file in files]\n",
    "\n",
    "    # Glob images' filepaths\n",
    "    splits = [glob_images(dir) for dir in ['crutch/train', 'crutch/test', 'crutch/valid',\n",
    "                                           'wheelchair/train', 'wheelchair/test', 'wheelchair/valid']]\n",
    "\n",
    "    # Read images\n",
    "    splits = [read_images(split) for split in splits]\n",
    "\n",
    "    # Resize crutch images to 416x416 to match wheelchair images\n",
    "    splits[:3] = [[cv2.resize(img, (416, 416)) for img in split]\n",
    "                  for split in splits[:3]]\n",
    "\n",
    "    # Concatenate wheelchair and crutch images\n",
    "    X_train, X_test, X_valid = [np.concatenate(\n",
    "        (splits[i], splits[i+3])) for i in range(3)]\n",
    "\n",
    "    # Create labels, 0 for wheelchair, 1 for crutch\n",
    "    y_train, y_test, y_valid = [np.concatenate(\n",
    "        (np.ones(len(splits[i])), np.zeros(len(splits[i+3])))) for i in range(3)]\n",
    "\n",
    "    # Save images and labels\n",
    "    splits = [X_train, X_test, X_valid, y_train, y_test, y_valid]\n",
    "    if not os.path.exists(dsSaveDir):\n",
    "        os.makedirs(dsSaveDir)\n",
    "    for i, split in enumerate(splits):\n",
    "        np.save(dsSaveDir + '/{}'.format(i+1), split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for some models into 2D array\n",
    "XRe_train, XRe_test, XRe_valid = [\n",
    "    X.reshape(X.shape[0], -1) for X in splits[:3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of iterations to converge: 153\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.94      0.93       174\n",
      "         1.0       0.95      0.94      0.94       207\n",
      "\n",
      "    accuracy                           0.94       381\n",
      "   macro avg       0.94      0.94      0.94       381\n",
      "weighted avg       0.94      0.94      0.94       381\n",
      "\n",
      "Confusion Matrix:\n",
      " [[0.94 0.06]\n",
      "  [0.06 0.94]]\n",
      "\n",
      "Accuracy: 0.94\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "try:\n",
    "    # Load model if already created\n",
    "    model = joblib.load(modelSaveDir + '/logisticRegression.joblib')\n",
    "except:\n",
    "    # Create model\n",
    "    model = LogisticRegression(max_iter=200, n_jobs=-1)\n",
    "\n",
    "    # Fit model using training data and validation data\n",
    "    model.fit(XRe_train, y_train)\n",
    "\n",
    "    # Save model\n",
    "    if not os.path.exists(modelSaveDir):\n",
    "        os.makedirs(modelSaveDir)\n",
    "    joblib.dump(model, modelSaveDir + '/logisticRegression.joblib')\n",
    "\n",
    "# Use validation data also for testing since sklearn doesn't support validation during training\n",
    "XRe_test = np.concatenate((XRe_test, XRe_valid))\n",
    "y_test = np.concatenate((y_test, y_valid))\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(XRe_test)\n",
    "\n",
    "# Print metrics\n",
    "print('No. of iterations to converge: {}'.format(model.n_iter_[0]))\n",
    "print('\\nClassification Report:\\n', classification_report(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', np.array2string(confusion_matrix(y_test, y_pred, normalize='true'),\n",
    "                                             precision=2, separator=' ', suppress_small=True).replace('\\n', '\\n '))\n",
    "print('\\nAccuracy: {:.2f}'.format(accuracy_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
